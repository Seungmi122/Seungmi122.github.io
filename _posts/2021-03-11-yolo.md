---
title: "[Paper Review] YOLO (You Look Only Once)"
excerpt: "See what is YOLO and how it works"
date: 2021-03-11 16:000 -0400
author : 오승미
use_math: true
tags :
- yolo
- object detection
- computer vision
category: [CV]


---

R-CNN, Fast R-CNN, Fast R-CNN are two-stage object detector: generate region proposals then execute classification.

**YOLO (You Look Only Once)** is a one-stage object detector that simultaneously processing two.

Advantages over two-stage models:

1. **fast!**
2. sees the whole image during training, conserving not only object appearance but contextual information
3. generalization - even outperforms R-CNN

However, compared to other two-stage object detection methods, it performs poor in accuracy. Depending on the aim of your project, we should consider these aspects carefully.

## Then, how it works?

Assume that we have an input like this.

<img align="center" width="500" height="500" src="/assets/2021-03-11-yolo_origin.png" alt="/assets/2021-03-11-yolo_origin.png" style="zoom:50%;" />

Divides the input into an *S × S* grid. Each grid cell predicts *B* bounding boxes and scores **confidence**, where confidence, equivalently,

$ \operatorname{Pr}(\text { Object }) * \text { IOU }_{\text {pred }}^{\text {truth }} $

and this reflect how confident the model is on the objectness and how accurate the predicted box is.

<img align="center" width="700" height="500" src="/assets/2021-03-11-yolo_object.png" alt="/assets/2021-03-11-yolo_object.png" style="zoom:50%;" />

Thus, each bounding box outputs five values, four coordinates and the confidence.

Also, the model predicts a class for each grid cell.

<img align="center" width="700" height="500" src="/assets/2021-03-11-yolo2.png" alt="/assets/2021-03-11-yolo2.png" style="zoom:50%;" />

Combining the classification and predicted box coordinates, the output would be:

<img align="center" width="700" height="500" src="/assets/2021-03-11-yolo3.png" alt="/assets/2021-03-11-yolo3.png" style="zoom:50%;" />

More specifically, we define class-specific confidence scores for each box,

$$ \operatorname{Pr}\left(\text { Class }_{i} \mid \text { Object }\right)   * \operatorname{Pr}(\text { Object }) * \text { IOU }_{\text {pred }}^{\text {truth }}=\operatorname{Pr}\left(\text { Class }_{i}\right) * \text { IOU }_{\text {pred }}^{\text {truth }} $$

and for large objects that cannot be located within the predicted box or some exceptional cases, we run **Non-Maximal Suppression (NMS)** to group out multiple boxes.

Finally,

<img align="center" width="700" height="500" src="/assets/2021-03-11-yolo4.png" alt="/assets/2021-03-11-yolo44.png" style="zoom:50%;" />

YOLO can predict on bounding box and classification at one stage by running through the below model architecture!

<img align="center" width="1000" height="400" src="/assets/2021-03-11-yoloy_model.png" alt="/assets/2021-03-11-yoloy.png" style="zoom:50%;" />

As you see, the output is 7 x 7 x 30, where the grid size is 7 x 7 and five output values for B bounding boxes (B=2 in this paper) plus 20 categories. 7 x 7 x (5x2 + 20). Clear :)

Additionally, YOLO has another limitation that it only predicts one class for each grid cell. This means that it is likely to miss information if there are multiple objects with different classes within a grid.

I'll cover later papers and check how people solve these limitations eventually next time :fire:



## Reference

- [https://arxiv.org/pdf/1506.02640.pdf](https://arxiv.org/pdf/1506.02640.pdf)
- [https://docs.google.com/presentation/d/1kAa7NOamBt4calBU9iHgT8a86RRHz9Yz2oh4-GTdX6M/edit#slide=id.g15092aa245_0_401](https://docs.google.com/presentation/d/1kAa7NOamBt4calBU9iHgT8a86RRHz9Yz2oh4-GTdX6M/edit#slide=id.g15092aa245_0_401)
